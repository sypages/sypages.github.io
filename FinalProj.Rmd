---
title: "Final Project"
author: "Sylvia"
date: "`r Sys.Date()`"
output: html_document
---

## What is data science?

I'm new to this. Four months ago, I would have said data science was about creating/maintaining/optimizing/storing databases and data retrieval. Thankfully, after a completing an introductory data science course, I'm better informed now. While these tasks are data focused, they tend to be in the domain of a database administrator. A data scientist, on the other hand, would gather and transform that data -- with the ultimate goal of extracting useful information to guide future decision making processes. 

For those just beginning their exploration of data science, I'd like to share a quick walk through of how to get started with a small project example. We'll skip through a lot of the how's of coding this project, but, where detailed or supplemental knowledge is needed to perform certain tasks, suggested resources are given.  

## Tools

First, it would be helpful if we are using the same tools. R, Python, and SQL are some of the more popular programs used in the data science and machine learning community. This tutorial will use R.

R is a free software environment for statistical computing and graphics and available at  https://www.r-project.org. 

Please read their guidelines on system requirements and instructions for downloading and installing on your computer.

We also want to download and use RStudio as our integrated design environment to make it easier to edit and run R code as well as have access to additional functionality. These extras are obtained by loading R packages. For information on R packages go to https://rstudio.com/products/rpackages/

Download RStudio from https://rstudio.com/products/rstudio/download/ and follow their install instructions. This video might be helpful https://www.youtube.com/watch?v=mcYcjH-1giM

Opening RStudio for the first time, it may just display a three paned window instead of a four paned window. 

![Three panes showing in RStudio.](3panes.png)

If the fourth pane is not diplaying, open an additional pane from the menu options File>New File>R Script. That opens a new editor pane on the left top. 

![Four panes showing in RStudio.](4panes.png)

The top left pane will be our main work space, where we can create multiple lines of code and save it for later use. The bottom left is the console where code can be run one at time. The environment/history pane is in the top right and files/plots are displayed in the bottom right pane. 

Learning the syntax for R will take a bit of research (stackoverflow.com is a good place to find R related answers).

For example, if we want to assign a value 1 to the expression a, in the editor pane we would type 
  a <- 1
to display the value of a, we would type 
  a
  
There are numerous ways to run your code in the editor pane. Here's three...
- the editor pane has a list of menu options at the top of the pane, select run
- RStudio's main menu has run options in the code menu option
- the shortcut is what I tend to us, on a mac to run all code, command + shift + return. To run just one line of code, command + return

![In the editor, assign a value to a.](1stcode.png)

RStudio sends the run code to the console pane and executes it. the results of the code is displayed in the console, with the exception of plots/graphs. Functions to create plots and graphs are display their results in the bottom right pane instead of the console.

![Results in the console.](1stcoderesults.png)
If you wanted to, the code could be entered directly in the console pane and run line by line. It's just harder to edit and save your code.

When working on a project, it's best to set up a directory to work from on your system and  identifying it in RStudio.

to display your current working directory, type...
	getwd()

to change your working directory, type ...
	setwd("~/mydirectory/project1")

Check out stackoverflow.com for helpful advice/answers on R.

Coming back to the additional functionality that you can add to R, R Packages I've found helpful are tidyverse (which includes ggplot2, dplyr, tidyr, purr, readr, and tibble amongst others).

It's a two step process to add additional functionality to R, install and load packages.
- in the console pane, type 
	install.packages("tidyverse").
- in the console pane, to load the installed package type
	library(tidyverse)

Because tidyverse is bundled with other packages, when we install tidyverse the other bundled packages are also installed. The catch is that the some of the other installed packages will need to be specifically loaded. At some point during the class I've used rvest, lubridate, magrittr, readxl, stringr, purrr, dplyr, ggplot2 and readr. 

Once a particular package is installed on your computer, it does not need to be installed again. Loading, on the other hand, will need to be done again (for example run library(tidyverse)) when a new project is started or RStudio is closed and reopened.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

## Data
Almost ready to get some data, first let's define our goal. 

Current news is dominated by coronavirus pandemic. With the limits on social interaction, business closures, and sheltering-in-place guidelines, it's a given that the economy is going to take a big hit. Congress has approved several much needed economic stimulus packages: coronavirus preparedness March 5th, 104 billion families first, March 18th, 2 trillion CARES Act March 27th, 484 billion covid-19 relief package April 24th, and now working on a 3 trillion HEROES Act. Even before the pandemic, many news outlets were highlighting the ballooning national debt. While these relief packages are sorely needed now, what will happens later? For those voters that are fiscally conservative, is there a political party that will be able to shrink this massive number once a covid-19 vaccine is available and the economy recovers.  

Let's look at historical data to help us answer this question. Let's evaluate the US public debt in relation to the political party of the president.

Now that our objective is defined, let's look for data.

Plugging "national debt" into your preferred search engine, will return many helpful sources (kaggle.com and data.world is also a place to look for datasets).
 
Data can be obtained in many different formats on the web. Sometimes it's available as a downloadable file such as a .csv, or excel file. Sometimes it's a webpage that needs to be "scrapped" for pertinent data. 

Once the data is downloaded. We'll need to clean it up. We may want to remove unnecessary columns, rename columns, reformat columns, change the datatype of certain columns (data and factor fields are especially of concern). https://www.superdatascience.com/blogs/wrangling-data-r-python and https://r4ds.had.co.nz/index.html could provide detailed guidance on the data cleaning also known as data wrangling.
## US National Debt

Data can be obtained from websites as downloadable data files in various formats such as csv, json, and exe.

We could grab data from https://treasurydirect.gov/govt/reports/pd/histdebt/histdebt_histo5.htm

cut and paste into excel or pages, save as an xlsx file
Before reading the excel file into RStudio, we need to load and activate the "readxl" package.

Possible places to get open source data are kaggle.com, and world.data.

```{r data_excel}
library(readxl)
debtDf <- read_excel("usDebt.xlsx")
head(debtDf)
```

Here we'll look at public data from 
https://fred.stlouisfed.org/series/GFDEBTN#0
Downloaded to our computer, with annual public debt numbers from 1969 to 2019, in millions of dollars.
```{r data}

debtDf <- read_csv("GFDEBTN.csv")
head(debtDf)
```


Create a graph for the numbers
```{r graph}
debtDf %>%   
  ggplot(aes(x=DATE, y=GFDEBTN)) +
    geom_line() +
    labs(x = "Year",
         y = "Debt in millions", title="US Public Debt from 1969 - 2019")
```

We'll modify the date to only show the year and change the column names

```{r rename}
debtDf<-rename(debtDf, year = DATE, debt = GFDEBTN )
debtDf$year = lubridate::year(debtDf$year)

debtDf
```

And re-display the graph in billions.

```{r new_graph}
debtDf %>%   
  ggplot(aes(x=year, y=debt/1000)) +
    geom_line() +
    labs(x = "Year",
         y = "Debt in billions", title="US Public Debt from 1969 - 2019")
```

Now we need to grab the presidental data from data.world

```{r}
presDf <- read_csv("by_date.csv")[,-4]
head(presDf)
```

```{r}
debtDf <- left_join(debtDf, presDf, by = "year")
debtDf
```

```{r}
debtDf %>%   
  ggplot(aes(x=year, y=debt/1000, color=party)) +
    geom_point() +
    labs(x = "Year",
         y = "Debt in billions", title="US Public Debt from 1969 - 2019")
```

Now let's see how the debt changes from year to year as a percentage.

```{r change_in_percent}
pctDf <- debtDf%>%
    group_by(party) %>%
    arrange(year) %>%
    mutate(pctChg = 100 * (debt - lag(debt))/lag(debt))

pctDf %>%   
  ggplot(aes(x=year, y=pctChg, color=party)) +
    geom_point() +
    labs(x = "Year",
         y = "Percentage of Annual Change", title="US Public Debt from 1969 - 2019")
pctDf
```

Now this is showing an interesting pattern. The percent change is pretty steady for most years, but notice the large spikes in the first year of a change over from one party to another.

Spikes:
1981, when a republican president came into power.

1993, when a democrat came in.

2001, when a republican came in.

2009,  when a democrat came in.

2017, when a republican came in.

This could be related to the fact that when a new president is elected, they move into the White House in Jan, but the budget for the next nine months is already set (sometimes there is a delay) by the previous president.
So, incoming presidents could be stuck with the previous president's budget until the end of the fiscal year in Sept, several months into their term. And even then the affect on the debt is not immediately felt.

This is just speculation, but we've got some interesting trends in our data, that justifies further investigation. 

## Wrap up
Our project tries to cover the different phases of data analysis: Data ingestion, Data manipulation, Data visualization, Data modeling, Publishing.
Data Science is a growing field which allows businesses and researchers to study and utilize the enormous amounts of data available on the web. This write-up relies heavily on the instruction provided by my UMD Data Science class, highlighting ideas that we have covered in class.

"the ability to understand that data and extract value from it.” - Hal Varian  

citations to follow in a separate posting (sorry, running out of time)